

### 一、离线扩容缩容

- 准备工作

  - mycat所在环境安装mysql客户端程序
  - mucat的lib目录下添加mysql的jdbc包
  - 对扩容缩容的表所有节点数据进行备份，以便迁移失败后数据恢复

- 扩容缩容步骤

  - 复制 schema.xml、rule.xml 并重命名为 newSchema.xml、newRule.xml 放于 conf 目录下

    ![image-20200821151406041](D:\github\study_line\dba\pic_lib\image-20200821151406041.png)

  - 修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配置参数（表的节点数、数据源、路由规则）

  - 修改 conf 目录下的 migrateTables.properties 配置文件，告诉工具哪些表需要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移，

    - 格式：

      ![image-20200821154605253](D:\github\study_line\dba\pic_lib\image-20200821154605253.png)

  - 修改 bin 目录下的 dataMigrate.sh 脚本文件，参数如下：

    - tempFileDir
      -  临时文件路径,目录不存在将自动创建
    - isAwaysUseMaster 
      - 默认 true:不论是否发生主备切换，都使用主数据源数据，false：使用当前数据源
    - mysqlBin
      - mysql bin 路径
    - cmdLength 
      - mysqldump 命令行长度限制 默认 110k 110*1024。在 LINUX 操作系统有限制单条命令行的长度是 128KB，也就是131072 字节，这个值可能不同操作系统不同内核都不一样，如果执行迁移时报 Cannot run program "sh": error=7, Argument list too long说明这个值设置大了，需要调小此值。*
    - charset 
      - 导入导出数据所用字符集 默认 utf8
    - deleteTempFileDir 
      - 完成扩容缩容后是否删除临时文件 默认为 true
    - threadCount 
      - 并行线程数（涉及生成中间文件和导入导出数据）默认为迁移程序所在主机环境的 cpu 核数*2
    - delThreadCount 
      - 每个数据库主机上清理冗余数据的并发线程数，默认为当前脚本程序所在主机 cpu 核数/2
    - queryPageSize
      - 读取迁移节点全部数据时一次加载的数据量 默认 10w 条

  - 停止 mycat 服务（如果可以确保扩容缩容过程中不会有写操作，也可以不停止 mycat 服务）

  - 通过 crt 等工具进入 mycat 根目录，执行 bin/ dataMigrate.sh 脚本

    - 开始扩容/缩容过程：

      ![image-20200821154934671](D:\github\study_line\dba\pic_lib\image-20200821154934671.png)

  - 扩容缩容成功后，将 newSchema.xml 和 newRule.xml 重命名为 schema.xml 和 rule.xml 并替换掉原文件，重启 mycat 服务，整个扩容缩容过程完成。

- 注意事项

  - 保证拆分表迁移数据前后路由规则一致。
  - 保证拆分表迁移数据前后拆分字段一致。
  - 全局表将被忽略。
  - 不要将非拆分表配置到 migrateTables.properties 文件中。
  - 暂时只支持拆分表使用 mysql 作为数据源的扩容缩容。

- 优化

  > dataMigrate.sh 脚本中影响数据迁移速度的有 4 个参数，正式迁移数据前可以先进行一次测试，通过调整以下参数进行优化获得一个最快的参数组合

  - threadCount 
    - 脚本执行所在主机的并行线程数（涉及生成中间文件和导入导出数据）默认为迁移程序所在主机环境的 cpu 核数乘以2
  - delThreadCount 
    - 每个数据库主机上清理冗余数据的并发线程数，默认为当前脚本程序所在主机 cpu 核数/2，同一主机上并发删除数据操作线程数过多可能会导致性能严重下降，可以逐步提高并发数，获取执行最快的线程个数。
  - queryPageSize 
    - 读取迁移节点全部数据时一次加载的数据量 默认 10w 条
  - cmdLength 
    - mysqldump 命令行长度限制 默认 110k 110*1024。尽量让这个值跟操作系统命令长度最大值一致，
    - 可以通过以下过程确定操作系统命令行最大长度限制：
      - 逐步减少 100000，直到不再报错
      - /bin/sh -c "/bin/true $(seq 1 100000)"
      - 获取不报错的值，通过 wc –c 统计字节数，结果即操作系统命令行最大长度限制（可能稍微小一些）
      - ![image-20200821155605159](D:\github\study_line\dba\pic_lib\image-20200821155605159.png)
      - ![image-20200821155616474](D:\github\study_line\dba\pic_lib\image-20200821155616474.png)











### 二、案例1，一致性hash

> 好处：
>
> ​	能减少需要迁移数据的节点，从而减少数据迁移操作
>
> 不足：
>
> ​	节点数据可能会变得不均匀，出现热点问题

#### 分片配置

- rule.xml：定义分片规则

  ```xml
  <!--
      tableRule 定义分片规则
          name：分片规则的名字。在 schema.xml 文件中调用。
          columns：根据数据库中此字段进行分片。
          algorithm：值是分片算法定义处的 name 属性。比如：murmur
  -->
  
  <tableRule name="sharding-by-murmur"> 
      <rule>
          <columns>SERIAL_NUMBER</columns>
          <algorithm>murmur</algorithm>
      </rule>
  </tableRule>
  <!-- 
      function 定义一致性 Hash 的参数。
      • seed：计算一致性哈希的对象使用的数值，默认是 0。
      • count：待分片的数据库节点数量，必须指定，否则没法分片。
      • virtualBucketTimes：虚拟节点。默认是 160 倍，也就是虚拟节点数是物理节点数的 160 倍。指定virtualBucketTimes 可以使一致性 hash 分片更加均匀。
      • bucketMapPath：用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的 murmur hash 值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西。必须是绝对路径，且可读写。
  -->
  <function name="murmur" class="io.mycat.route.function.PartitionByMurmurHash">
      <property name="seed">0</property>
      <property name="count">2</property>
      <property name="virtualBucketTimes">160</property>
      <!-- 
  		<property name="weightMapFile">weightMapFile</property>
      	<property name="bucketMapPath">/home/usr/mycat/bucketMapPath</property> 
  	-->
  </function>
  ```

  


- schema.xml:定义逻辑库，表、分片节点等内容

  ```xml
  <?xml version="1.0" encoding="utf-8"?>
  <!DOCTYPE mycat:schema SYSTEM "schema.dtd">
  <mycat:schema xmlns:mycat="http://io.mycat/">
      <schema name="mycat" checkSQLschema="false" sqlMaxLimit="100">
          <table name="T_CMS_ORDER" primaryKey="ORDER_ID" dataNode="dn202_3316" rule="sharding-by-murmur" />
      </schema>
      <dataNode name="dn202_3316" dataHost="lh202_1" database="poc" />
      <dataHost name="lh202_1" maxCon="2000" minCon="10" balance="0" writeType="0" dbType="mysql"
      dbDriver="native">
          <heartbeat>select user()</heartbeat>
          <writeHost host="master_host-m1" url="10.21.17.202:3316" user="usr" password="pwd"></writeHost>
          <writeHost host="savle_host-m1" url="10.21.17.201:3317" user="usr" password="pwd"></writeHost>
      </dataHost>
  </mycat:schema>
  ```

- server.xml：定义用户以及系统相关变量，如端口等。没有太高要求的可以只修改数据库部分

  ```xml
  <user name="mycat">
  	<property name="password">usr</property>
  	<property name="schemas">pwd</property>
  </user>
  ```

  

#### 数据迁移

- 配置修改

  - rule.xml

    ```xml
    <!-- 需要把节点的数量从 2 个节点扩为 3 个节点。 -->
    <function name="murmur" class="io.mycat.route.function.PartitionByMurmurHash">
        <property name="seed">0</property>
        <property name="count">3</property>
        <property name="virtualBucketTimes">160</property>
        <!-- <property name="weightMapFile">weightMapFile</property>
        <property name="bucketMapPath">/home/usr/mycat/bucketMapPath</property> -->
    </function>
    ```

  - schema.xml

    ```xml
    <!--需要添加新节点的 dataNode 和 dataHost 信息，以及在 schema 中的 table 标签下把新增节点的 dataNode 的 name 增加到 dataNode 的值中 -->
    
    <?xml version="1.0" encoding="utf-8"?>
    <!DOCTYPE mycat:schema SYSTEM "schema.dtd">
    <mycat:schema xmlns:mycat="http://io.mycat/">
        <schema name="mycat" checkSQLschema="false" sqlMaxLimit="100">
            <table name="T_CMS_ORDER" primaryKey="ORDER_ID" dataNode="dn202_3316,dn201_3316" rule="sharding-by-murmur" />
        </schema>
        <dataNode name="dn202_3316" dataHost="lh202_1" database="poc" />
        <dataNode name="dn201_3316" dataHost="lh201_1" database="poc" />
        <dataHost name="lh202_1" maxCon="2000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native">
            <heartbeat>select user()</heartbeat>
                <writeHost host="master_host-m1" url="10.21.17.202:3316" user="usr" password="pwd"></writeHost>
                <writeHost host="savle_host-m1" url="10.21.17.201:3317" user="usr" password="pwd"></writeHost>
                </dataHost>
                <dataHost name="lh201_1" maxCon="2000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native">
            <heartbeat>select user()</heartbeat>
            <writeHost host="master_host-m1" url="10.21.17.201:3316" user="usr" password="pwd"></writeHost>
            <writeHost host="savle_host-m1" url="10.21.17.202:3317" user="usr" password="pwd"></writeHost>
        </dataHost>
    </mycat:schema>
    ```



#### 开始迁移

- 使用 io.mycat.util.rehasher.RehashLauncher 类进行数据迁移,参数以命令行的形式进行载入,如:

  ```java
  -jdbcDriver=xxxxx -jdbcUrl=.... -host=192.168.1.1:3316 -user=xxxx -password=xxxx -database=xxxx
  ```

- jdbcDriver：数据库驱动。如 com.mysql.jdbc.Driver。

- jdbcUrl：连接数据库的 url，不同数据库不一样。如 : jdbc:mysql://10.21.17.201:3316/mycat?rewriteBatchedStatements=true

- host：包括主机名和端口，形如 ip:port。如 10.21.100.86:3316。

- user：连接数据库的用户名。如 usr。

- database：数据库的名字。如 mycat。

- password：连接数据库的密码。如 pwd。

- tablesFile：记录数据表的文件，一个表一行。

- shardingField：数据库中进行分片的字段。

- rehashHostsFile：这个参数没有用到，按照当时的要求，这个类一次只处理一个节点，所以不需要配置

- hashType：是 MURMUR hash 还是 mod hash。

- seed：生成一致性 hash 对象的参数。默认为 0。

- virtualBucketTimes：虚拟节点的倍数。默认为 160

- weightMapFile：节点的权重，没有指定权重的节点默认是 1。以 properties 文件的格式填写，以从 0 开

- 始到 count-1 的整数值也就是节点索引为 key，以节点权重值为值。所有权重值必须是正整数，否则以 1 代替。

- rehashNodeDir：一个 linux 目录，这个程序执行完了，把计算结果输出到这个目录，一个表一个文件存在这个目录里，文件名是表名。

  > 如果你觉得使用命令行的方式去读取配置不是那么方便，你也可以自己定义读取配置文件的算法，只要能保
  > 证 io.mycat.util.rehasher.RehashLauncher 这个类能够读到所有的配置就可以了。比如使用 properties 文件保
  > 存配置文件(每次修改配置文件后都需要重新编译)，本着怎么方便怎么写代码的原则，就是这么任性
  
- 运行 io.mycat.util.rehasher.RehashLauncher 后生成的文件格式如下:

  ![image-20200821170757582](D:\github\study_line\dba\pic_lib\image-20200821170757582.png)


#### 迁移脚本

- ReHashRouter.sh

```shell
rehashNode=$1
expanNode=$2
order_fn="$3"
if [ "$#" = "0" ]; then
echo "Please input parameter, for example:"
echo "ReRouter.sh 192.168.84.13 192.168.84.14 /home/mycat/T_CMS_ORDER "
echo " "
exit
fi;
echo "需要进行迁移的主机总量为:$#, 主机 IP 列表如下:"
for i in "$@"
do
echo "$i"
done
echo " "
#取出 rehash 需要的 SerNum(已经用 in 拼接好)
for n in `cat $order_fn`
do
condOrder=$n
done
echo "************* 导出 *************"
date
# 1) 首先调用 mysqldump 进行数据导出
echo "开始导出主机:$ 表:T_CMS_ORDER."
mysqldump -h$rehashNode -P3316 -upoc -ppoc123 poc T_CMS_ORDER --default-character-set=utf8 --
extended-insert=false --no-create-info --add-locks=false --complete-insert --where=" SERIAL_NUMBER in
$condOrder " > ./T_CMS_ORDER_temp.sql
echo "导出结束."
echo " "
echo "************* 导入 *************"
date
# 2) 调用 mycat 接口进行数据导入
echo "开始导入 T_CMS_ORDER 表数据"
mysql -h$expanNode -P8066 -upoc -ppoc123 poc --default-character-set=utf8 < ./T_CMS_ORDER_temp.sql
echo "导入结束."
echo " "
echo "************* 删除数据 *************"
date
# 3) 当前两步都无误的情况下,删除最初的导出数据.
echo "开始删除已导出的数据表:."
mysql -h$rehashNode -P3316 -upoc -ppoc123 -e "use poc; DELETE FROM T_CMS_ORDER WHERE
SERIAL_NUMBER in $condOrder ; commit; "
echo "删除结束."
echo " "
echo "************* 清空临时文件 *************"
date
# 4) 清空临时文件
rm ./t_cms_order_temp.sql
echo "清空临时文件"
echo "#####################主机:$rehashNode 处理完成#####################"
date
echo " "
echo "ReHash 运行完毕."
```

- 授权：chmod +x ReHashRouter.sh
- 运行：./ReHashRouter.sh 10.21.17.200 10.21.17.201 /home/mycat/T_CMS_ORDER







### 三、管理命令与监控

> 数据端口默认 8066，管理端口默认 9066 ，如果需要修改需要配置 serve.xml

命令总览：`show @@help`

```
| show @@time.current                                          | Report current timestamp    
| show @@time.startup                                          | Report startup timestamp                   |
| show @@version   获取 MyCAT 的版本                             | Report Mycat Server version                |
| show @@server                                                | Report server status                       |
| show @@threadpool                                            | Report threadPool status                   |
| show @@database   显示 MyCAT 的数据库的列表                     |Report databases     
| show @@datanode   显示 MyCAT 的数据节点的列表                   | Report dataNodes                           |
| show @@datanode where schema = ?                             | Report dataNodes                           |
| show @@datasource     查看数据源状态                           | Report dataSources                         |
| show @@datasource where dataNode = ?                         | Report dataSources                         |
| show @@datasource.synstatus                                  | Report datasource data synchronous         |
| show @@datasource.syndetail where name=?                     | Report datasource data synchronous detail  |
| show @@datasource.cluster                                    | Report datasource galary cluster variables |
| show @@processor                                             | Report processor status                    |
| show @@command                                               | Report commands status                     |
| show @@connection 获取 Mycat 的前端连接状态，即应用与 mycat 的连接 | Report connection status                   |
| show @@cache       查看 mycat 缓存                            | Report system cache usage                  |
| show @@backend  查看后端连接状态                                | Report backend connection status           |
| show @@session                                               | Report front session details               |
| show @@connection.sql                                        | Report connection sql                      |
| show @@sql.execute                                           | Report execute status                      |
| show @@sql.detail where id = ?                               | Report execute detail status               |
| show @@sql                                                   | Report SQL list                            |
| show @@sql.high                                              | Report Hight Frequency SQL                 |
| show @@sql.slow                                              | Report slow SQL                            |
| show @@sql.resultset                                         | Report BIG RESULTSET SQL                   |
| show @@sql.sum                                               | Report  User RW Stat                       |
| show @@sql.sum.user                                          | Report  User RW Stat                       |
| show @@sql.sum.table                                         | Report  Table RW Stat                      |
| show @@parser                                                | Report parser status                       |
| show @@router                                                | Report router status                       |
| show @@heartbeat   报告心跳状态                                | Report heartbeat status                    |
| show @@heartbeat.detail where name=?                         | Report heartbeat current detail            |
| show @@slow where schema = ?                                 | Report schema slow sql                     |
| show @@slow where datanode = ?                               | Report datanode slow sql                   |
| show @@sysparam                                              | Report system param                        |
| show @@syslog limit=?                                        | Report system mycat.log                    |
| show @@white                                                 | show mycat white host                      |
| show @@white.set=?,?                                         | set mycat white host,[ip,user]             |
| show @@directmemory=1 or 2                                   | show mycat direct memory usage             |
| show @@check_global -SCHEMA= ? -TABLE=? -retry=? -interval=? | check mycat global table consistency       |
| switch @@datasource name:index                               | Switch dataSource                          |
| kill @@connection id1,id2,...                                | Kill the specified connections             |
| stop @@heartbeat name:time                                   | Pause dataNode heartbeat                   |
| reload @@config  更新配置文件                                  |Reload basic config from file              |
| reload @@config_all                                          | Reload all config from file                |
| reload @@route                                               | Reload route config from file              |
| reload @@user                                                | Reload user config from file               |
| reload @@sqlslow=                                            | Set Slow SQL Time(ms)                      |
| reload @@user_stat                                           | Reset show @@sql  @@sql.sum @@sql.slow     |
| rollback @@config                                            | Rollback all config from memory            |
| rollback @@route                                             | Rollback route config from memory          |
| rollback @@user                                              | Rollback user config from memory           |
| reload @@sqlstat=open                                        | Open real-time sql stat analyzer           |
| reload @@sqlstat=close                                       | Close real-time sql stat analyzer          |
| offline                                                      | Change MyCat status to OFF                 |
| online                                                       | Change MyCat status to ON                  |
| clear @@slow where schema = ?                                | Clear slow sql by schema                   |
| clear @@slow where datanode = ?                              | Clear slow sql by datanode                 |
+--------------------------------------------------------------+--------------------------------------------+
```



- show @@datanode;

  - 显示 MyCAT 的数据节点的列表

  - ![image-20200907105416884](D:\github\study_line\dba\pic_lib\image-20200907105416884.png)

  - NAME 表示 dataNode 的名称；

  - dataHost”表示对应 dataHost 属性的值，即数据主机；

  - ACTIVE 表示活跃连接数；

  - IDLE 表示闲置连接数；

  - SIZE 对应总连接数量

  - ```mysql
    # 查找对应的 schema 下面的 dataNode 列表
    show @@datanode where schema = ?
    ```

- show @@heartbeat

  - 报告心跳状态
  - ![image-20200907105949052](D:\github\study_line\dba\pic_lib\image-20200907105949052.png)
  - RS_CODE 状态
    - OK_STATUS = 1;正常状态
    - ERROR_STATUS = -1; 连接出错
    - TIMEOUT_STATUS = -2;连接超时
    - INIT_STATUS = 0; 初始化状态
  - 若节点故障，会连续默认 5 个周期检测，心跳连续失败，就会变成-1，节点故障确认，然后可能发生切换

- show @@connection

  - 该命令用于获取 Mycat 的前端连接状态，即应用与 mycat 的连接
  - ![image-20200907110746825](D:\github\study_line\dba\pic_lib\image-20200907110746825.png)

- kill @@connection id,id,id

  - 用于杀掉连接。

- show @@cache

  - 查看 mycat 缓存
  - ![image-20200907111931633](D:\github\study_line\dba\pic_lib\image-20200907111931633.png)
  - SQLRouteCache：sql 路由缓存。
  - TableID2DataNodeCache ： 缓存表主键与分片对应关系。
  - ER_SQL2PARENTID ： 缓存 ER 分片中子表与父表关系。

- show @@datasource

  - 查看数据源状态，如果配置了主从，或者多主可以切换

  - ![image-20200907131204239](D:\github\study_line\dba\pic_lib\image-20200907131204239.png)

  - switch @@datasource name:index

    - 切换数据源
    - name：schema 中配置的 dataHost 中 name。
    - index：schema 中配置的 dataHost 的 writeHost index 位标，即按照配置顺序从上到下的一次顺 序，从 0
      开始。
    - 切换数据源时，会将原数据源所有的连接池中连接关闭，并且从新数据源创建新连接，此时 mycat 服务不可
      用。
    - dnindex.properties 文件在记录了当前的活跃 writer。

  - reload@@user_stat

    - 工作在 9066 端口，用来将客户端执行 下面统计命令命令之后所缓存的信息清空

      - show @@sql ;
        - 显示出刚刚执行 SQL 语句详细的相关信息
      - show @@sql.sum ;
      -  show@@slow.success ;

      









































































